[
  {
    "objectID": "ST588Homework9.html",
    "href": "ST588Homework9.html",
    "title": "ST588 Homework 9",
    "section": "",
    "text": "##HW 8: Basic Modeling Practice ### First order of business…load libraries that are needed for the project:\nlibrary(readr)\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(gganimate)\nlibrary(tidymodels)\nlibrary(parsnip)\nlibrary(glmnet)\nlibrary(rpart.plot)\nlibrary(baguette)\nlibrary(ranger)"
  },
  {
    "objectID": "ST588Homework9.html#split-the-data",
    "href": "ST588Homework9.html#split-the-data",
    "title": "ST588 Homework 9",
    "section": "Split the Data",
    "text": "Split the Data\nWe’ll split the data into a training and test set (75/25). We’ll use the strata argument to stratify the split on the seasons variable.\nFirst, we’ll use the initial_split(), training(), and testing() functions to create the splits:\n\nset.seed(10)\n#create split with 75% data in training set and 25% in test set, and name the sets\nrental_split &lt;- initial_split(data5, prop = 0.75, strata =\"seasons\")\nrental_train &lt;- training(rental_split)\nrental_test &lt;- testing(rental_split)\nrental_train\n\n# A tibble: 263 × 12\n# Groups:   date, seasons [263]\n   date       seasons holiday    sumCount sumRain sumSnow meanTemp meanHumidity\n   &lt;date&gt;     &lt;fct&gt;   &lt;fct&gt;         &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;\n 1 2018-09-02 Autumn  No Holiday    26881     0         0     25.0         54.5\n 2 2018-09-03 Autumn  No Holiday    10802    34.5       0     23.6         82.2\n 3 2018-09-04 Autumn  No Holiday    29529     0         0     23.3         71.6\n 4 2018-09-07 Autumn  No Holiday    30381     1.5       0     22.2         56.9\n 5 2018-09-08 Autumn  No Holiday    29813     0         0     21.7         48.7\n 6 2018-09-09 Autumn  No Holiday    28354     0         0     22.0         49.5\n 7 2018-09-11 Autumn  No Holiday    31694     0         0     21.6         48.0\n 8 2018-09-13 Autumn  No Holiday    30991     0         0     23.4         62.3\n 9 2018-09-14 Autumn  No Holiday    28199     0.5       0     23.5         67.2\n10 2018-09-15 Autumn  No Holiday    25079     0.2       0     23.2         75.9\n# ℹ 253 more rows\n# ℹ 4 more variables: meanWind &lt;dbl&gt;, meanVis &lt;dbl&gt;, meanDP_C &lt;dbl&gt;,\n#   meanSR &lt;dbl&gt;\n\n\n263/353 = ~ 75%, so that looks like we successfully created the right proportions for our training/test datasets.\n263 rows in the training dataset, which is not evenly divisible by 10. Each fold will have 26 observations, and one fold with have 29.\n\n#calculate fold size by dividing by number of folds (10)\nsize_fold &lt;- floor(nrow(rental_train)/10)\nsize_fold\n\n[1] 26\n\n\nNext, we’ll set a seed and randomly sample the folds into a list.\n\nset.seed(10)\n#randomly create starting indices for each fold\nrandom_indices &lt;- sample(1:nrow(rental_train), size = nrow(rental_train), replace=FALSE)\nhead(random_indices)\n\n[1] 137  72 211 143  24  13\n\n\nWe can see above the first index of each fold.\nNext, we’ll create a list in which to save our folds, then cycle through the random indices vector to place the observations from each fold in the list accordingly.\n\nfolds &lt;- list()\n\nfor(i in 1:10){\n  if (i&lt;10) {\n    fold_index &lt;- seq(from = (i-1)*size_fold + 1, to = i*size_fold, by=1)\n    folds[[i]] &lt;- rental_train[random_indices[fold_index], ]\n  } else {\n    fold_index &lt;- seq(from = (i-1)*size_fold +1, to=length(random_indices), by =1)\n    folds[[i]] &lt;- rental_train[random_indices[fold_index], ]\n  }\n}\n\n#check out the first fold:\nfolds[[1]]\n\n# A tibble: 26 × 12\n# Groups:   date, seasons [26]\n   date       seasons holiday    sumCount sumRain sumSnow meanTemp meanHumidity\n   &lt;date&gt;     &lt;fct&gt;   &lt;fct&gt;         &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;\n 1 2018-06-14 Summer  No Holiday    23818    29       0      21.7          74.4\n 2 2018-03-20 Spring  No Holiday    11515     0       0       5.04         40.6\n 3 2017-12-18 Winter  No Holiday     2620     3.4    59.7    -1.97         77  \n 4 2018-06-22 Summer  No Holiday    34079     0       0      24.7          47.9\n 5 2018-10-08 Autumn  No Holiday    29362     0       0      14.7          46.5\n 6 2018-09-20 Autumn  No Holiday    14282     5       0      19.0          80.2\n 7 2018-05-11 Spring  No Holiday    26649     0       0      15.8          63.5\n 8 2018-09-11 Autumn  No Holiday    31694     0       0      21.6          48.0\n 9 2018-01-12 Winter  No Holiday     4111     0       0     -10.7          36.2\n10 2018-01-13 Winter  No Holiday     3503     0.4     2.2    -4.56         63.8\n# ℹ 16 more rows\n# ℹ 4 more variables: meanWind &lt;dbl&gt;, meanVis &lt;dbl&gt;, meanDP_C &lt;dbl&gt;,\n#   meanSR &lt;dbl&gt;\n\n\nLet’s check out the 10th fold…does it contain 29 observations?\n\nfolds[[10]]\n\n# A tibble: 29 × 12\n# Groups:   date, seasons [29]\n   date       seasons holiday    sumCount sumRain sumSnow meanTemp meanHumidity\n   &lt;date&gt;     &lt;fct&gt;   &lt;fct&gt;         &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;\n 1 2018-03-25 Spring  No Holiday    10963     0         0     9.62         65.8\n 2 2018-07-22 Summer  No Holiday    18563     0         0    31.6          50.9\n 3 2018-04-26 Spring  No Holiday    25670     0         0    15.1          50.1\n 4 2018-09-02 Autumn  No Holiday    26881     0         0    25.0          54.5\n 5 2018-04-23 Spring  No Holiday      977    61         0     9.43         93.8\n 6 2018-05-29 Spring  No Holiday    24355     1         0    21.5          66.4\n 7 2018-03-30 Spring  No Holiday    19301     0         0    14.7          55.0\n 8 2018-06-29 Summer  No Holiday    30297     6.5       0    24.7          79.2\n 9 2018-05-27 Spring  No Holiday    28991     0         0    20.6          42.1\n10 2018-02-11 Winter  No Holiday     2850     0         0    -5.99         40.5\n# ℹ 19 more rows\n# ℹ 4 more variables: meanWind &lt;dbl&gt;, meanVis &lt;dbl&gt;, meanDP_C &lt;dbl&gt;,\n#   meanSR &lt;dbl&gt;\n\n\nYes! There are 29 observations in Fold #10!"
  },
  {
    "objectID": "ST588Homework9.html#fitting-mlr-models",
    "href": "ST588Homework9.html#fitting-mlr-models",
    "title": "ST588 Homework 9",
    "section": "Fitting MLR Models",
    "text": "Fitting MLR Models\nWe’ll create 3 recipes to preprocess the data…\n\nRecipe 1\nWe’ll change the role of date, create a weekday/weekend factor variable from the date, standardize the numberic variables, and create dummy variables for seasons, holiday, and the new variables.\n\nbike_rec1 &lt;- \n  recipe(sumCount ~ ., data=rental_train) %&gt;%\n  #change date to an ID role so that it is not included in fit, but is included in dataset\n  update_role(date, new_role = \"ID\") %&gt;%\n  #change date to day of the week\n  step_mutate(\"date\" = weekdays(date)) %&gt;%\n  #transform day of week into week/weekend factor for inclusion in model fitting\n  step_mutate(\"date\" = factor(if_else(date %in% c(\"Saturday\", \"Sunday\"), \"weekend\", \"weekday\"))) %&gt;%\n  #make all nominal predictors into dummy variables\n  step_dummy(all_nominal_predictors()) %&gt;%\n  #cneter and scale numeric variables, except do not include dummy variables, dates, or outcomes\n  step_normalize(starts_with(c(\"sum\", \"mean\")), -all_date_predictors(), -all_outcomes()) #%&gt;%\n#  prep(training=rental_train) %&gt;%\n#  bake(rental_train)\n\n#bike_rec1\n\nWe’ll next create the same recipe, with interaction terms between seasons and holiday, seasons and temp, and temp and rainfall.\n\nbike_rec2 &lt;- \n  recipe(sumCount ~ ., data=rental_train) %&gt;%\n  update_role(date, new_role = \"ID\") %&gt;%\n  step_mutate(\"date\" = weekdays(date)) %&gt;%\n  step_mutate(\"date\" = factor(if_else(date %in% c(\"Saturday\", \"Sunday\"), \"weekend\", \"weekday\"))) %&gt;%\n  step_dummy(all_nominal_predictors()) %&gt;%\n  step_normalize(starts_with(c(\"sum\", \"mean\")), -all_date_predictors(), -all_outcomes()) %&gt;%\n  step_interact(terms = ~ starts_with(\"seasons\"):starts_with(\"holiday\") + starts_with(\"seasons\"):meanTemp + meanTemp:sumRain) #%&gt;%\n#  prep(training=rental_train) %&gt;%\n#  bake(rental_train)\n\n#bike_rec2\n\nOn to recipe three that includes quadratic terms:\n\nbike_rec3 &lt;- \n  recipe(sumCount ~ ., data=rental_train) %&gt;%\n  update_role(date, new_role = \"ID\") %&gt;%\n  step_mutate(\"date\" = weekdays(date)) %&gt;%\n  step_mutate(\"date\" = factor(if_else(date %in% c(\"Saturday\", \"Sunday\"), \"weekend\", \"weekday\"))) %&gt;%\n  step_dummy(all_nominal_predictors()) %&gt;%\n  step_normalize(starts_with(c(\"sum\", \"mean\")), -all_date_predictors(), -all_outcomes()) %&gt;%\n  step_poly(all_numeric_predictors(), -starts_with(c(\"seasons\", \"holiday\")), degree = 2) #%&gt;%\n  #prep(training=rental_train) %&gt;%\n  #bake(rental_train)\n\n#bike_rec3\n\nNext, we’ll create our model using the lm engine:\n\nrentalMod &lt;- linear_reg() %&gt;%\n  #use \"lm\", or linear model engine for model fitting\n  set_engine(\"lm\")\n\nNext, we’ll create flow to fit the model and out put tidy estimates of the parameters:\n\n#create workflow for recipe 1 that starts with the recipe and fits the preprocessed data through the model engine specified in \"rentalMod\" object.\nrental_wfl_1 &lt;- workflow() %&gt;%\n  add_recipe(bike_rec1) %&gt;%\n  add_model(rentalMod)\n#rental_wfl_1\n\nNext well just fit Recipe 1 to test out our system:\n\n#this code initiates the fitting of the preprocessed data through the model on the training dataset\nrental_fit1 &lt;- rental_wfl_1 %&gt;%\n  fit(rental_train)\nrental_fit1 %&gt;%\n  tidy()\n\n# A tibble: 13 × 5\n   term               estimate std.error statistic  p.value\n   &lt;chr&gt;                 &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 (Intercept)          19423.     1265.    15.3   6.56e-38\n 2 sumRain              -1597.      353.    -4.53  9.24e- 6\n 3 sumSnow               -368.      294.    -1.25  2.12e- 1\n 4 meanTemp             -4793.     4803.    -0.998 3.19e- 1\n 5 meanHumidity         -2939.     1799.    -1.63  1.04e- 1\n 6 meanWind              -626.      315.    -1.99  4.78e- 2\n 7 meanVis               -142.      395.    -0.361 7.19e- 1\n 8 meanDP_C              9880.     5608.     1.76  7.93e- 2\n 9 meanSR                3999.      509.     7.85  1.19e-13\n10 seasons_Spring       -4650.      885.    -5.25  3.18e- 7\n11 seasons_Summer       -3466.     1096.    -3.16  1.75e- 3\n12 seasons_Winter       -8191.     1196.    -6.85  5.85e-11\n13 holiday_No.Holiday    2706.     1196.     2.26  2.45e- 2\n\n\nWe’ll do 10 fold CV on the training data:\n\n#split the training dataset into 10 folds\nrental_10_fold &lt;- vfold_cv(rental_train, 10)\n#resample each of the 10 folds and put the specified workflow\nrental_CV_fits_1 &lt;- rental_wfl_1 %&gt;%\n  fit_resamples(rental_10_fold)\nrental_CV_fits_1\n\n# Resampling results\n# 10-fold cross-validation \n# A tibble: 10 × 4\n   splits           id     .metrics         .notes          \n   &lt;list&gt;           &lt;chr&gt;  &lt;list&gt;           &lt;list&gt;          \n 1 &lt;split [236/27]&gt; Fold01 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n 2 &lt;split [236/27]&gt; Fold02 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n 3 &lt;split [236/27]&gt; Fold03 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n 4 &lt;split [237/26]&gt; Fold04 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n 5 &lt;split [237/26]&gt; Fold05 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n 6 &lt;split [237/26]&gt; Fold06 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n 7 &lt;split [237/26]&gt; Fold07 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n 8 &lt;split [237/26]&gt; Fold08 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n 9 &lt;split [237/26]&gt; Fold09 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n10 &lt;split [237/26]&gt; Fold10 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n\n\nNext we’ll get the metrics:\n\nrental_CV_fits_1 %&gt;%\n  collect_metrics()\n\n# A tibble: 2 × 6\n  .metric .estimator     mean     n  std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;         &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard   4424.       10 200.     Preprocessor1_Model1\n2 rsq     standard      0.790    10   0.0203 Preprocessor1_Model1\n\n\nNow, we’ll repeat starting from the workflow step for each recipe. First, workflow for recipe 2, fit model, then do 10-fold CV on test dataset, then get metrics for each model:\n\n#create workflow for recipe 2\nrental_wfl_2 &lt;- workflow() %&gt;%\n  add_recipe(bike_rec2) %&gt;%\n  add_model(rentalMod)\nrental_wfl_2\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_mutate()\n• step_mutate()\n• step_dummy()\n• step_normalize()\n• step_interact()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLinear Regression Model Specification (regression)\n\nComputational engine: lm \n\n#create workflow for recipe 3\nrental_wfl_3 &lt;- workflow() %&gt;%\n  add_recipe(bike_rec3) %&gt;%\n  add_model(rentalMod)\nrental_wfl_3\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_mutate()\n• step_mutate()\n• step_dummy()\n• step_normalize()\n• step_poly()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLinear Regression Model Specification (regression)\n\nComputational engine: lm \n\n#fit model 2\nrental_fit2 &lt;- rental_wfl_2 %&gt;%\n  fit(rental_train)\nrental_fit2 %&gt;%\n  tidy()\n\n# A tibble: 20 × 5\n   term                                estimate std.error statistic  p.value\n   &lt;chr&gt;                                  &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 (Intercept)                           17269.     1591.    10.9   1.20e-22\n 2 sumRain                               -1794.      346.    -5.18  4.66e- 7\n 3 sumSnow                                -309.      211.    -1.47  1.44e- 1\n 4 meanTemp                              -4462.     3716.    -1.20  2.31e- 1\n 5 meanHumidity                          -3621.     1364.    -2.65  8.46e- 3\n 6 meanWind                               -436.      225.    -1.94  5.41e- 2\n 7 meanVis                                 417.      306.     1.36  1.74e- 1\n 8 meanDP_C                              11065.     4241.     2.61  9.65e- 3\n 9 meanSR                                 2842.      373.     7.62  5.78e-13\n10 seasons_Spring                        -3049.     2837.    -1.07  2.84e- 1\n11 seasons_Summer                        20176.     3153.     6.40  8.03e-10\n12 seasons_Winter                        -5806.     2424.    -2.40  1.74e- 2\n13 holiday_No.Holiday                     4772.     1633.     2.92  3.81e- 3\n14 seasons_Spring_x_holiday_No.Holiday   -1112.     2900.    -0.383 7.02e- 1\n15 seasons_Summer_x_holiday_No.Holiday   -1514.     2747.    -0.551 5.82e- 1\n16 seasons_Winter_x_holiday_No.Holiday   -2271.     2061.    -1.10  2.72e- 1\n17 seasons_Spring_x_meanTemp              5997.     1146.     5.23  3.57e- 7\n18 seasons_Summer_x_meanTemp            -19270.     1520.   -12.7   1.29e-28\n19 seasons_Winter_x_meanTemp              -584.     1458.    -0.401 6.89e- 1\n20 meanTemp_x_sumRain                    -1317.      425.    -3.10  2.18e- 3\n\n#fit model 3\nrental_fit3 &lt;- rental_wfl_3 %&gt;%\n  fit(rental_train)\nrental_fit3 %&gt;%\n  tidy()\n\n# A tibble: 21 × 5\n   term               estimate std.error statistic  p.value\n   &lt;chr&gt;                 &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 (Intercept)          16531.     1269.   13.0    9.46e-30\n 2 seasons_Spring       -4578.      865.   -5.29   2.71e- 7\n 3 seasons_Summer        -160.     1167.   -0.137  8.91e- 1\n 4 seasons_Winter       -4079.     1312.   -3.11   2.10e- 3\n 5 holiday_No.Holiday    3723.     1124.    3.31   1.07e- 3\n 6 sumRain_poly_1      -30478.     6320.   -4.82   2.50e- 6\n 7 sumRain_poly_2        3347.     4445.    0.753  4.52e- 1\n 8 sumSnow_poly_1        -136.     4647.   -0.0293 9.77e- 1\n 9 sumSnow_poly_2       -4268.     4375.   -0.976  3.30e- 1\n10 meanTemp_poly_1    -229695.    89008.   -2.58   1.05e- 2\n# ℹ 11 more rows\n\n#10-fold CV recipe 2\n#rental_10_fold_2 &lt;- vfold_cv(rental_train, 10)\nrental_CV_fits_2 &lt;- rental_wfl_2 %&gt;%\n  fit_resamples(rental_10_fold)\nrental_CV_fits_2\n\n# Resampling results\n# 10-fold cross-validation \n# A tibble: 10 × 4\n   splits           id     .metrics         .notes          \n   &lt;list&gt;           &lt;chr&gt;  &lt;list&gt;           &lt;list&gt;          \n 1 &lt;split [236/27]&gt; Fold01 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n 2 &lt;split [236/27]&gt; Fold02 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n 3 &lt;split [236/27]&gt; Fold03 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n 4 &lt;split [237/26]&gt; Fold04 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n 5 &lt;split [237/26]&gt; Fold05 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n 6 &lt;split [237/26]&gt; Fold06 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n 7 &lt;split [237/26]&gt; Fold07 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n 8 &lt;split [237/26]&gt; Fold08 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n 9 &lt;split [237/26]&gt; Fold09 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n10 &lt;split [237/26]&gt; Fold10 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n\n#10-fold CV recipe 3\n#rental_10_fold_3 &lt;- vfold_cv(rental_train, 10)\nrental_CV_fits_3 &lt;- rental_wfl_3 %&gt;%\n  fit_resamples(rental_10_fold)\nrental_CV_fits_3\n\n# Resampling results\n# 10-fold cross-validation \n# A tibble: 10 × 4\n   splits           id     .metrics         .notes          \n   &lt;list&gt;           &lt;chr&gt;  &lt;list&gt;           &lt;list&gt;          \n 1 &lt;split [236/27]&gt; Fold01 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n 2 &lt;split [236/27]&gt; Fold02 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n 3 &lt;split [236/27]&gt; Fold03 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n 4 &lt;split [237/26]&gt; Fold04 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n 5 &lt;split [237/26]&gt; Fold05 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n 6 &lt;split [237/26]&gt; Fold06 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n 7 &lt;split [237/26]&gt; Fold07 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n 8 &lt;split [237/26]&gt; Fold08 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n 9 &lt;split [237/26]&gt; Fold09 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n10 &lt;split [237/26]&gt; Fold10 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n\n\nHere, we’ll display the metrics for recipe 2:\n\nrental_CV_fits_2 %&gt;%\n  collect_metrics()\n\n# A tibble: 2 × 6\n  .metric .estimator     mean     n  std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;         &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard   3366.       10 224.     Preprocessor1_Model1\n2 rsq     standard      0.878    10   0.0176 Preprocessor1_Model1\n\n\n…And for recipe 3:\n\nrental_CV_fits_3 %&gt;%\n  collect_metrics()\n\n# A tibble: 2 × 6\n  .metric .estimator     mean     n  std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;         &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard   4351.       10 156.     Preprocessor1_Model1\n2 rsq     standard      0.804    10   0.0194 Preprocessor1_Model1\n\n\nRecipe 2 has the lowest RMSE and highest R-squared.\nWe need to create a metric set using yardstick::metric_set() in order to specify the mae metrics to be output in all the models.\n\nfinal_metrics &lt;- metric_set(rmse, mae)\n\nWe’ll use the “best” model on the test dataset and see how it fares:\n\n#use last_fit() function to collect metrics from recipe/model 2 and display\ntestResults &lt;- last_fit(rental_wfl_2, split = rental_split, metrics = final_metrics)\nmle_metrics &lt;- collect_metrics(testResults)\nmle_metrics\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard       3340. Preprocessor1_Model1\n2 mae     standard       2525. Preprocessor1_Model1\n\n\nRMSE for test dataset is 3339.891 with r-squared of 0.8928. These values seem to match closely to the estimates from the training dataset using recipe 2."
  },
  {
    "objectID": "ST588Homework9.html#lasso-regression-tree-bagged-tree-and-random-forest-models",
    "href": "ST588Homework9.html#lasso-regression-tree-bagged-tree-and-random-forest-models",
    "title": "ST588 Homework 9",
    "section": "LASSO, Regression Tree, Bagged Tree, and Random Forest models:",
    "text": "LASSO, Regression Tree, Bagged Tree, and Random Forest models:\nWe’ll start with the first model for Homework 9, the LASSO model.\nWe need to start with the recipe. Since it is best to standardize the predictors for LASSO models, we’ll create a similar recipe as for the previous LM recipes from homework 8 in which the numerical predictors were normlized. We’ll create the same three recipes to test the LASSO model family:\n\n#create the LASSO model specification using the glmnet engine\nLASSO_mod &lt;- linear_reg(penalty = tune(), mixture = 1) %&gt;%\n  set_engine(\"glmnet\")\n\nNext, we’ll create the LASSO model workflows:\n\nLASSO_wfl_1 &lt;- workflow() %&gt;%\n  add_recipe(bike_rec1) %&gt;%\n  add_model(LASSO_mod)\nLASSO_wfl_1\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n4 Recipe Steps\n\n• step_mutate()\n• step_mutate()\n• step_dummy()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLinear Regression Model Specification (regression)\n\nMain Arguments:\n  penalty = tune()\n  mixture = 1\n\nComputational engine: glmnet \n\nLASSO_wfl_2 &lt;- workflow() %&gt;%\n  add_recipe(bike_rec2) %&gt;%\n  add_model(LASSO_mod)\nLASSO_wfl_2\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_mutate()\n• step_mutate()\n• step_dummy()\n• step_normalize()\n• step_interact()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLinear Regression Model Specification (regression)\n\nMain Arguments:\n  penalty = tune()\n  mixture = 1\n\nComputational engine: glmnet \n\nLASSO_wfl_3 &lt;- workflow() %&gt;%\n  add_recipe(bike_rec3) %&gt;%\n  add_model(LASSO_mod)\nLASSO_wfl_3\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_mutate()\n• step_mutate()\n• step_dummy()\n• step_normalize()\n• step_poly()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLinear Regression Model Specification (regression)\n\nMain Arguments:\n  penalty = tune()\n  mixture = 1\n\nComputational engine: glmnet \n\n\nFor the LASSO family, next, we’ll fit the model using the tune_grid function:\n\nLASSO_grid_1 &lt;- LASSO_wfl_1 %&gt;%\n  tune_grid(resamples = rental_10_fold,\n            grid = grid_regular(penalty(), levels = 200))\n\nLASSO_grid_1\n\n# Tuning results\n# 10-fold cross-validation \n# A tibble: 10 × 4\n   splits           id     .metrics           .notes          \n   &lt;list&gt;           &lt;chr&gt;  &lt;list&gt;             &lt;list&gt;          \n 1 &lt;split [236/27]&gt; Fold01 &lt;tibble [400 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 2 &lt;split [236/27]&gt; Fold02 &lt;tibble [400 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 3 &lt;split [236/27]&gt; Fold03 &lt;tibble [400 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 4 &lt;split [237/26]&gt; Fold04 &lt;tibble [400 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 5 &lt;split [237/26]&gt; Fold05 &lt;tibble [400 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 6 &lt;split [237/26]&gt; Fold06 &lt;tibble [400 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 7 &lt;split [237/26]&gt; Fold07 &lt;tibble [400 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 8 &lt;split [237/26]&gt; Fold08 &lt;tibble [400 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 9 &lt;split [237/26]&gt; Fold09 &lt;tibble [400 × 5]&gt; &lt;tibble [0 × 3]&gt;\n10 &lt;split [237/26]&gt; Fold10 &lt;tibble [400 × 5]&gt; &lt;tibble [0 × 3]&gt;\n\n\nLet’s show the LASSO penalty metrics:\n\nLASSO_grid_1[1, \".metrics\"][[1]]\n\n[[1]]\n# A tibble: 400 × 5\n    penalty .metric .estimator .estimate .config               \n      &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;                 \n 1 1   e-10 rmse    standard       5172. Preprocessor1_Model001\n 2 1.12e-10 rmse    standard       5172. Preprocessor1_Model002\n 3 1.26e-10 rmse    standard       5172. Preprocessor1_Model003\n 4 1.41e-10 rmse    standard       5172. Preprocessor1_Model004\n 5 1.59e-10 rmse    standard       5172. Preprocessor1_Model005\n 6 1.78e-10 rmse    standard       5172. Preprocessor1_Model006\n 7 2.00e-10 rmse    standard       5172. Preprocessor1_Model007\n 8 2.25e-10 rmse    standard       5172. Preprocessor1_Model008\n 9 2.52e-10 rmse    standard       5172. Preprocessor1_Model009\n10 2.83e-10 rmse    standard       5172. Preprocessor1_Model010\n# ℹ 390 more rows\n\n\nThen, we’ll collect those metrics that include RMSE:\n\nLASSO_grid_1 %&gt;%\n  collect_metrics() %&gt;%\n  filter(.metric == \"rmse\")\n\n# A tibble: 200 × 7\n    penalty .metric .estimator  mean     n std_err .config               \n      &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;                 \n 1 1   e-10 rmse    standard   4413.    10    191. Preprocessor1_Model001\n 2 1.12e-10 rmse    standard   4413.    10    191. Preprocessor1_Model002\n 3 1.26e-10 rmse    standard   4413.    10    191. Preprocessor1_Model003\n 4 1.41e-10 rmse    standard   4413.    10    191. Preprocessor1_Model004\n 5 1.59e-10 rmse    standard   4413.    10    191. Preprocessor1_Model005\n 6 1.78e-10 rmse    standard   4413.    10    191. Preprocessor1_Model006\n 7 2.00e-10 rmse    standard   4413.    10    191. Preprocessor1_Model007\n 8 2.25e-10 rmse    standard   4413.    10    191. Preprocessor1_Model008\n 9 2.52e-10 rmse    standard   4413.    10    191. Preprocessor1_Model009\n10 2.83e-10 rmse    standard   4413.    10    191. Preprocessor1_Model010\n# ℹ 190 more rows\n\n\nNow we’ll plot these metrics:\n\nLASSO_grid_1 %&gt;% \n  collect_metrics() %&gt;%\n  filter(.metric == \"rmse\") %&gt;%\n  ggplot(aes(penalty, mean, color = .metric)) +\n  geom_line() +\n  labs(title = \"LASSO Model 1\")\n\n\n\n\n\n\n\n\nLet’s repeat the LASSO steps for the models 2 and 3 (adding interaction and quadratic terms, respectively)\n\nLASSO_grid_2 &lt;- LASSO_wfl_2 %&gt;%\n  tune_grid(resamples = rental_10_fold,\n            grid = grid_regular(penalty(), levels = 200))\n\nLASSO_grid_2\n\n# Tuning results\n# 10-fold cross-validation \n# A tibble: 10 × 4\n   splits           id     .metrics           .notes          \n   &lt;list&gt;           &lt;chr&gt;  &lt;list&gt;             &lt;list&gt;          \n 1 &lt;split [236/27]&gt; Fold01 &lt;tibble [400 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 2 &lt;split [236/27]&gt; Fold02 &lt;tibble [400 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 3 &lt;split [236/27]&gt; Fold03 &lt;tibble [400 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 4 &lt;split [237/26]&gt; Fold04 &lt;tibble [400 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 5 &lt;split [237/26]&gt; Fold05 &lt;tibble [400 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 6 &lt;split [237/26]&gt; Fold06 &lt;tibble [400 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 7 &lt;split [237/26]&gt; Fold07 &lt;tibble [400 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 8 &lt;split [237/26]&gt; Fold08 &lt;tibble [400 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 9 &lt;split [237/26]&gt; Fold09 &lt;tibble [400 × 5]&gt; &lt;tibble [0 × 3]&gt;\n10 &lt;split [237/26]&gt; Fold10 &lt;tibble [400 × 5]&gt; &lt;tibble [0 × 3]&gt;\n\nLASSO_grid_3 &lt;- LASSO_wfl_3 %&gt;%\n  tune_grid(resamples = rental_10_fold,\n            grid = grid_regular(penalty(), levels = 200))\n\nLASSO_grid_3\n\n# Tuning results\n# 10-fold cross-validation \n# A tibble: 10 × 4\n   splits           id     .metrics           .notes          \n   &lt;list&gt;           &lt;chr&gt;  &lt;list&gt;             &lt;list&gt;          \n 1 &lt;split [236/27]&gt; Fold01 &lt;tibble [400 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 2 &lt;split [236/27]&gt; Fold02 &lt;tibble [400 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 3 &lt;split [236/27]&gt; Fold03 &lt;tibble [400 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 4 &lt;split [237/26]&gt; Fold04 &lt;tibble [400 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 5 &lt;split [237/26]&gt; Fold05 &lt;tibble [400 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 6 &lt;split [237/26]&gt; Fold06 &lt;tibble [400 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 7 &lt;split [237/26]&gt; Fold07 &lt;tibble [400 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 8 &lt;split [237/26]&gt; Fold08 &lt;tibble [400 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 9 &lt;split [237/26]&gt; Fold09 &lt;tibble [400 × 5]&gt; &lt;tibble [0 × 3]&gt;\n10 &lt;split [237/26]&gt; Fold10 &lt;tibble [400 × 5]&gt; &lt;tibble [0 × 3]&gt;\n\n\nLet’s show the LASSO penalty metrics for models 2…:\n\nLASSO_grid_2[1, \".metrics\"][[1]]\n\n[[1]]\n# A tibble: 400 × 5\n    penalty .metric .estimator .estimate .config               \n      &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;                 \n 1 1   e-10 rmse    standard       3196. Preprocessor1_Model001\n 2 1.12e-10 rmse    standard       3196. Preprocessor1_Model002\n 3 1.26e-10 rmse    standard       3196. Preprocessor1_Model003\n 4 1.41e-10 rmse    standard       3196. Preprocessor1_Model004\n 5 1.59e-10 rmse    standard       3196. Preprocessor1_Model005\n 6 1.78e-10 rmse    standard       3196. Preprocessor1_Model006\n 7 2.00e-10 rmse    standard       3196. Preprocessor1_Model007\n 8 2.25e-10 rmse    standard       3196. Preprocessor1_Model008\n 9 2.52e-10 rmse    standard       3196. Preprocessor1_Model009\n10 2.83e-10 rmse    standard       3196. Preprocessor1_Model010\n# ℹ 390 more rows\n\n\n…And let’s show the LASSO penalty metrics for model 3:\n\nLASSO_grid_3[1, \".metrics\"][[1]]\n\n[[1]]\n# A tibble: 400 × 5\n    penalty .metric .estimator .estimate .config               \n      &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;                 \n 1 1   e-10 rmse    standard       4489. Preprocessor1_Model001\n 2 1.12e-10 rmse    standard       4489. Preprocessor1_Model002\n 3 1.26e-10 rmse    standard       4489. Preprocessor1_Model003\n 4 1.41e-10 rmse    standard       4489. Preprocessor1_Model004\n 5 1.59e-10 rmse    standard       4489. Preprocessor1_Model005\n 6 1.78e-10 rmse    standard       4489. Preprocessor1_Model006\n 7 2.00e-10 rmse    standard       4489. Preprocessor1_Model007\n 8 2.25e-10 rmse    standard       4489. Preprocessor1_Model008\n 9 2.52e-10 rmse    standard       4489. Preprocessor1_Model009\n10 2.83e-10 rmse    standard       4489. Preprocessor1_Model010\n# ℹ 390 more rows\n\n\nNext, we’ll plot the penalties and RMSE values for LASSO Models 2 and 3:\n\nLASSO_grid_2 %&gt;% \n  collect_metrics() %&gt;%\n  filter(.metric == \"rmse\") %&gt;%\n  ggplot(aes(penalty, mean, color = .metric)) +\n  geom_line() +\n  labs(title = \"LASSO Model 2\")\n\n\n\n\n\n\n\n\n\nLASSO_grid_3 %&gt;% \n  collect_metrics() %&gt;%\n  filter(.metric == \"rmse\") %&gt;%\n  ggplot(aes(penalty, mean, color = .metric)) +\n  geom_line() +\n  labs(title = \"LASSO Model 3\")\n\n\n\n\n\n\n\n\nNext, we’ll determine the tuning parameter that is associated with the best RMSE value and determine that model’s coefficients using select_best() and finalize_workflow for each LASSO model.\n\nlowest_rmse_LASSO_1 &lt;- LASSO_grid_1 %&gt;%\n  select_best(metric = \"rmse\")\n\nlowest_rmse_LASSO_2 &lt;- LASSO_grid_2 %&gt;%\n  select_best(metric = \"rmse\")\n\nlowest_rmse_LASSO_3 &lt;- LASSO_grid_3 %&gt;%\n  select_best(metric = \"rmse\")\n\nrbind(lowest_rmse_LASSO_1, lowest_rmse_LASSO_2, lowest_rmse_LASSO_3)\n\n# A tibble: 3 × 2\n       penalty .config               \n         &lt;dbl&gt; &lt;chr&gt;                 \n1 0.0000000001 Preprocessor1_Model001\n2 1            Preprocessor1_Model200\n3 1            Preprocessor1_Model200\n\n\nModel 2 has the lowest RMSE, and the best LASSO model for model 2 aligns with the penalty of 1.\nLet’s fit model 2 on our training set.\n\nLASSO_final &lt;- LASSO_wfl_2 %&gt;%\n  finalize_workflow(lowest_rmse_LASSO_2) %&gt;%\n  fit(rental_train)\ntidy(LASSO_final)\n\n# A tibble: 20 × 3\n   term                                estimate penalty\n   &lt;chr&gt;                                  &lt;dbl&gt;   &lt;dbl&gt;\n 1 (Intercept)                           17541.       1\n 2 sumRain                               -1913.       1\n 3 sumSnow                                -344.       1\n 4 meanTemp                               -176.       1\n 5 meanHumidity                          -2067.       1\n 6 meanWind                               -425.       1\n 7 meanVis                                 456.       1\n 8 meanDP_C                               6013.       1\n 9 meanSR                                 2821.       1\n10 seasons_Spring                        -2656.       1\n11 seasons_Summer                        19203.       1\n12 seasons_Winter                        -6296.       1\n13 holiday_No.Holiday                     4447.       1\n14 seasons_Spring_x_holiday_No.Holiday   -1558.       1\n15 seasons_Summer_x_holiday_No.Holiday    -799.       1\n16 seasons_Winter_x_holiday_No.Holiday   -1739.       1\n17 seasons_Spring_x_meanTemp              6013.       1\n18 seasons_Summer_x_meanTemp            -18975.       1\n19 seasons_Winter_x_meanTemp              -642.       1\n20 meanTemp_x_sumRain                    -1238.       1\n\n\nNow, let’s fit the LASSO model 2 on the test set:\n\nLASSO_test &lt;- LASSO_wfl_2 %&gt;%\n  finalize_workflow(lowest_rmse_LASSO_2) %&gt;%\n  last_fit(rental_split, metrics = final_metrics) %&gt;%\n  collect_metrics()"
  },
  {
    "objectID": "ST588Homework9.html#regression-tree-model",
    "href": "ST588Homework9.html#regression-tree-model",
    "title": "ST588 Homework 9",
    "section": "Regression Tree Model",
    "text": "Regression Tree Model\nFirst, we’ll do similar steps as for above models…we’ll define the model engine and create a workflow for the Regression Tree model. We will fit on recipes 1 and 3, as Regression Tree models already take interactions into account.\n\n#define model engine.\ntree_mod &lt;- decision_tree(tree_depth = tune(),\n                          min_n = 20,\n                          cost_complexity = tune()) %&gt;%\n  set_engine(\"rpart\") %&gt;%\n  set_mode(\"regression\")\n\n#create workflow for each regression tree model:\ntree_wfl_1 &lt;- workflow() %&gt;%\n  add_recipe(bike_rec1) %&gt;%\n  add_model(tree_mod)\n\ntree_wfl_2 &lt;- workflow() %&gt;%\n  add_recipe(bike_rec3) %&gt;%\n  add_model(tree_mod)\n\nNext, we’ll create the tuning grid and specify number of each of tree_depth and cost_complexity values to tune to.\n\ntree_grid &lt;- grid_regular(cost_complexity(),\n                           tree_depth(),\n                           levels = c(10,5))\n\nThen, we’ll use tune_grid() with the tree_grid object from above.\n\ntree_fits_1 &lt;- tree_wfl_1 %&gt;%\n  tune_grid(resamples = rental_10_fold,\n            grid = tree_grid)\n\ntree_fits_2 &lt;- tree_wfl_2 %&gt;%\n  tune_grid(resamples = rental_10_fold,\n            grid = tree_grid)\n\nThen, we’ll plot the tree_fits_1 and…\n\ntree_fits_1 %&gt;%\n  collect_metrics() %&gt;%\n  mutate(tree_depth = factor(tree_depth)) %&gt;%\n  ggplot(aes(cost_complexity, mean, color = tree_depth)) +\n  geom_line(size = 1.0, alpha = 0.5) +\n  geom_point(size = 2) +\n  facet_wrap(~ .metric, scales = \"free\", nrow=2) +\n  scale_x_log10(labels = scales::label_number()) +\n  scale_color_viridis_d(option = \"mako\", begin = .9, end= 0)\n\n\n\n\n\n\n\n\n…tree_fits_2 metrics:\n\ntree_fits_2 %&gt;%\n  collect_metrics() %&gt;%\n  mutate(tree_depth = factor(tree_depth)) %&gt;%\n  ggplot(aes(cost_complexity, mean, color = tree_depth)) +\n  geom_line(size = 1.0, alpha = 0.5) +\n  geom_point(size = 2) +\n  facet_wrap(~ .metric, scales = \"free\", nrow=2) +\n  scale_x_log10(labels = scales::label_number()) +\n  scale_color_viridis_d(option = \"mako\", begin = .9, end= 0)\n\n\n\n\n\n\n\n\nIt looks like the regression tree already accounts for the higher order variables, since both plots appear very similar. This matches with what I’ve read in various descriptions of the technique.\nNow, we will select_best to get the best model’s tuning parameters, then finalize the model and create a workflow that contains the best model with the lowest cost_complexity using finalize_workflow.\n\ntree_best_params &lt;- select_best(tree_fits_1, metric = \"rmse\")\n\ntree_final_wfl &lt;- tree_wfl_1 %&gt;%\n  finalize_workflow(tree_best_params)\n\nNow, we’ll fit the best regression tree model on the test dataset:\n\n#use last_fit()on rental_split\ntree_final_fit &lt;- tree_final_wfl %&gt;%\n  last_fit(rental_split, metrics = final_metrics)\n\n#collect metrics on the final_fit on the test dataset:\ntree_final_metrics &lt;- tree_final_fit %&gt;%\n  collect_metrics()\n\ntree_final_metrics\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard       3211. Preprocessor1_Model1\n2 mae     standard       2542. Preprocessor1_Model1\n\n\nLastly, we’ll plot the regression tree:\n\ntree_final_model &lt;- extract_workflow(tree_final_fit)\n\ntree_final_model %&gt;%\n  extract_fit_engine() %&gt;%\n  rpart.plot::rpart.plot(roundint = FALSE)"
  },
  {
    "objectID": "ST588Homework9.html#bagged-tree-model",
    "href": "ST588Homework9.html#bagged-tree-model",
    "title": "ST588 Homework 9",
    "section": "Bagged Tree Model",
    "text": "Bagged Tree Model\nHere we’ll use specify a model engine, create a workflow, fit CV folds, check log_loss function, get best tuning parameter and refit on test dataset.\nFirst, specify model engine:\n\nbag_mod &lt;- bag_tree(tree_depth = 5, min_n = 10, cost_complexity = tune()) %&gt;%\n  set_engine(\"rpart\") %&gt;%\n  set_mode(\"regression\")\n\nNext, we’ll creat the workflow for the Bagged Tree model:\n\nbag_wfl &lt;- workflow() %&gt;%\n  add_recipe(bike_rec1) %&gt;%\n  add_model(bag_mod)\n\nNext, fit the CV folds:\n\nbag_fit &lt;- bag_wfl %&gt;%\n  tune_grid(resamples = rental_10_fold,\n            grid=grid_regular(cost_complexity(),\n                              levels = 15)\n            )\n\nNext, we’ll select the best bagged tree model by using select_best:\n\nbag_best_params &lt;- select_best(bag_fit, metric = \"rmse\")\nbag_best_params\n\n# A tibble: 1 × 2\n  cost_complexity .config              \n            &lt;dbl&gt; &lt;chr&gt;                \n1       0.0000139 Preprocessor1_Model09\n\n\nNow, we’ll fit on test dataset using the tuning parameter from above:\n\nbag_final_wfl &lt;- bag_wfl %&gt;%\n  finalize_workflow(bag_best_params)\n\nbag_final_fit &lt;- bag_final_wfl %&gt;%\n  last_fit(rental_split, metrics = final_metrics)\n\nbag_final_metrics &lt;- bag_final_fit %&gt;% collect_metrics()\n\nbag_final_metrics\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard       2774. Preprocessor1_Model1\n2 mae     standard       2160. Preprocessor1_Model1\n\n\nNow, we’ll plot variable importance:\n\nbag_final_model &lt;- extract_fit_engine(bag_final_fit)\nbag_final_model$imp %&gt;%\n  mutate(term = factor(term, levels = term)) %&gt;%\n  ggplot(aes(x=term, y=value, levels = term)) +\n  geom_bar(stat = \"identity\") +\n  coord_flip()\n\n\n\n\n\n\n\n\nIt Appears as if meanTemp is the most important predictor according to the Bagged Tree model."
  },
  {
    "objectID": "ST588Homework9.html#on-to-random-forest",
    "href": "ST588Homework9.html#on-to-random-forest",
    "title": "ST588 Homework 9",
    "section": "On to Random Forest!",
    "text": "On to Random Forest!\nNow we’ll repeat the same steps as above to demonstrate the random forest model using the Tidymodels package.\nFirst, we’ll specify the model engine.\n\nrf_mod &lt;- rand_forest(mtry = tune()) %&gt;%\n  set_engine(\"ranger\", importance = \"impurity\") %&gt;%\n  set_mode(\"regression\")\n\nThen, we’ll create the Random Forest workflow:\n\nrf_wfl &lt;- workflow() %&gt;%\n  add_recipe(bike_rec1) %&gt;%\n  add_model(rf_mod)\n\nNow, fit the CV folds:\n\nrf_fit &lt;- rf_wfl %&gt;%\n  tune_grid(resamples = rental_10_fold,\n            grid = 7)\n\nWe’ll select the best tuning parameter:\n\nrf_best_params &lt;- select_best(rf_fit, metric=\"rmse\")\nrf_best_params\n\n# A tibble: 1 × 2\n   mtry .config             \n  &lt;int&gt; &lt;chr&gt;               \n1    11 Preprocessor1_Model3\n\n\nNow…refit the test set with the best tuning parameter:\n\nrf_final_wfl &lt;- rf_wfl %&gt;%\n  finalize_workflow(rf_best_params)\nrf_final_fit &lt;- rf_final_wfl %&gt;%\n  last_fit(rental_split, metrics = final_metrics)\n\nrf_final_metrics &lt;- rf_final_fit %&gt;%\n  collect_metrics()\nrf_final_metrics\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard       2919. Preprocessor1_Model1\n2 mae     standard       2234. Preprocessor1_Model1\n\n\nNow, we’ll extract the fit engine and plot importance:\n\nrf_final_model &lt;- extract_fit_engine(rf_final_fit)\n\nrf_importance &lt;- as_tibble(stack(rf_final_model$variable.importance)) \n\n\nnames(rf_importance) &lt;- c(\"value\", \"term\")\n\nrf_importance &lt;-arrange(rf_importance, (\"value\"))\n\nrf_importance %&gt;%\n  mutate(term = fct_reorder(term, desc(value))) %&gt;%\n  ggplot(aes(x=term, y=value, levels = term)) +\n  geom_bar(stat = \"identity\") +\n  coord_flip()\n\n\n\n\n\n\n\n\nNow, let’s compare all of the models and determine which is best using rmse and mae:\n\n#I somehow got \"mlr\" specified as \"mle\" throughout.  Correcting here in comparison table:\nmle_metrics$source &lt;- \"mlr\"\nLASSO_test$source &lt;- \"LASSO\"\ntree_final_metrics$source &lt;- \"regression_tree\"\nbag_final_metrics$source &lt;- \"bagged_tree\"\nrf_final_metrics$source &lt;- \"random_forest\"\n\ncomparison &lt;- as_tibble(rbind(mle_metrics,\n      LASSO_test,\n      tree_final_metrics,\n      bag_final_metrics,\n      rf_final_metrics))\n\ncomparison\n\n# A tibble: 10 × 5\n   .metric .estimator .estimate .config              source         \n   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;                &lt;chr&gt;          \n 1 rmse    standard       3340. Preprocessor1_Model1 mlr            \n 2 mae     standard       2525. Preprocessor1_Model1 mlr            \n 3 rmse    standard       3335. Preprocessor1_Model1 LASSO          \n 4 mae     standard       2520. Preprocessor1_Model1 LASSO          \n 5 rmse    standard       3211. Preprocessor1_Model1 regression_tree\n 6 mae     standard       2542. Preprocessor1_Model1 regression_tree\n 7 rmse    standard       2774. Preprocessor1_Model1 bagged_tree    \n 8 mae     standard       2160. Preprocessor1_Model1 bagged_tree    \n 9 rmse    standard       2919. Preprocessor1_Model1 random_forest  \n10 mae     standard       2234. Preprocessor1_Model1 random_forest  \n\n\nIt looks like the Bagged Tree is the best model on the test dataset. The Bagged Tree model has the lowest rmse, and the second lowest MAE."
  },
  {
    "objectID": "ST588Homework9.html#use-fit-to-fit-best-bagged-tree-to-full-dataset.",
    "href": "ST588Homework9.html#use-fit-to-fit-best-bagged-tree-to-full-dataset.",
    "title": "ST588 Homework 9",
    "section": "Use fit() to fit best (Bagged Tree) to full dataset.",
    "text": "Use fit() to fit best (Bagged Tree) to full dataset.\nLastly, we’ll fit the best model, the Bagged Tree model, on the entire Dataset!\n\nfinal_model &lt;- bag_final_wfl %&gt;%\n  fit(data5)\nfinal_model&lt;- extract_fit_engine(final_model)\nfinal_model$imp %&gt;%\n  mutate(term = factor(term, levels = term)) %&gt;%\n  ggplot(aes(x=term, y=value, levels = term)) +\n  geom_bar(stat = \"identity\") +\n  coord_flip()"
  }
]